import os
from dotenv import load_dotenv
from pathlib import Path

# LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate
from langchain_community.document_loaders import PyPDFLoader
from langchain.memory import ConversationBufferMemory

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class OboeChatbot:
    """
    'ì˜¤ë³´ì—' ì•¨ë²” ë¶„ì„ PDFë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” RAG ì±—ë´‡ í´ë˜ìŠ¤
    """
    def __init__(self):
        # .env íŒŒì¼ì—ì„œ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
        self.pdf_filename = os.getenv("PDF_FILENAME")
        
        # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •
        base_dir = Path(__file__).parent
        self.pdf_path = base_dir / self.pdf_filename
        
        # ë²¡í„° ìŠ¤í† ì–´ ë° ëŒ€í™” ì²´ì¸ ì´ˆê¸°í™”
        self.vector_store = self._get_or_create_vector_store()
        self.chain = self._setup_conversational_chain()

    def _get_or_create_vector_store(self):
        """PDF íŒŒì¼ë¡œë¶€í„° ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.pdf_path.exists():
            raise FileNotFoundError(
                f"'{self.pdf_filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                f"backend í´ë”ì— íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        
        try:
            loader = PyPDFLoader(str(self.pdf_path))
            documents = loader.load()
            
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
            split_docs = text_splitter.split_documents(documents)
            
            embeddings = OpenAIEmbeddings()
            vectorstore = FAISS.from_documents(split_docs, embedding=embeddings)
            
            print("âœ… PDF ë¬¸ì„œ ë¡œë“œ ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ.")
            return vectorstore
        except Exception as e:
            print(f"ğŸš¨ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

    def _setup_conversational_chain(self):
        """LangChainì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”í˜• ê²€ìƒ‰ ì²´ì¸ì„ ì„¤ì •í•©ë‹ˆë‹¤."""
        llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7, streaming=True)
        
        # _setup_conversational_chain ë©”ì„œë“œ ë‚´ë¶€
        prompt_template = """
        ë‹¹ì‹ ì€ ì‚¬ìš©ìì™€ 1:1ë¡œ ëŒ€í™”í•˜ëŠ” ì¹œì ˆí•˜ê³  ë§¤ë ¥ì ì¸ 'ìŒì•… íë ˆì´í„°'ì…ë‹ˆë‹¤. 
        ë‹¹ì‹ ì˜ ì´ë¦„ì€ 'ì˜¤ë³´'ì´ë©°, ì–‘í™ì›ì˜ 'ì˜¤ë³´ì—' ì•¨ë²”ì— ëŒ€í•´ ëª¨ë¥´ëŠ” ê²ƒì´ ì—†ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
        ë”±ë”±í•œ ì •ë³´ ì „ë‹¬ì´ ì•„ë‹Œ, ìƒëŒ€ë°©ì˜ ëˆˆë†’ì´ì— ë§ì¶° ì„¤ëª…í•˜ê³  ê°ìƒì„ ê³µìœ í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

        --- í˜ë¥´ì†Œë‚˜ ë° ëŒ€í™” ê·œì¹™ ---
        1.  **ì¸ì‚¬ì™€ ê³µê°**: ë‹µë³€ì„ ì‹œì‘í•  ë•Œ, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ "ì¢‹ì€ ì§ˆë¬¸ì´ë„¤ìš”!", "ê·¸ ë¶€ë¶„ì— ëŒ€í•´ ê¶ê¸ˆí•˜ì…¨êµ°ìš”." ì™€ ê°™ì´ ê°€ë³ê²Œ ê³µê°í•˜ë©° ì‹œì‘í•´ì£¼ì„¸ìš”.
        2.  **ë‘ê´„ì‹ ì„¤ëª…**: í•­ìƒ í•µì‹¬ ê²°ë¡ ì„ ë¨¼ì € ë§í•˜ê³ , ê·¸ í›„ì— ê·¼ê±°ë¥¼ ë¶„ì„ ë¬¸ì„œ ë‚´ìš©ì—ì„œ ì°¾ì•„ 2-3ë¬¸ì¥ìœ¼ë¡œ ë¶€ì—° ì„¤ëª…í•´ì£¼ì„¸ìš”.
        3.  **ë¹„ìœ ì™€ ì˜ˆì‹œ í™œìš©**: ì–´ë ¤ìš´ ìŒì•… ìš©ì–´ë‚˜ ê°œë…ì€ "ë§ˆì¹˜ ~ì²˜ëŸ¼ìš”.", "ì˜ˆë¥¼ ë“¤ë©´ ì´ëŸ° ëŠë‚Œì´ì£ ." ì™€ ê°™ì´ ì¼ìƒì ì¸ ë¹„ìœ ë¥¼ ë“¤ì–´ ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        4.  **ì •ë³´ ì¶œì²˜ ëª…ì‹œ (ì„ íƒì )**: ë‹µë³€ì˜ ì‹ ë¢°ë„ë¥¼ ìœ„í•´, ë¬¸ì„œì˜ ì–´ë–¤ ë‚´ìš©ì„ ì°¸ê³ í–ˆëŠ”ì§€ ê°€ë³ê²Œ ì–¸ê¸‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: "ì•¨ë²” ë¶„ì„ ë¬¸ì„œì—ì„œëŠ” ì´ ë¶€ë¶„ì„ ~ë¼ê³  í‘œí˜„í•˜ê³  ìˆì–´ìš”.")
        5.  **ëŒ€í™” ìœ ë„**: ë‹µë³€ ë§ˆì§€ë§‰ì—ëŠ” í•­ìƒ "í˜¹ì‹œ ë” ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹ ê°€ìš”?", "ì´ ê³¡ì˜ ë‹¤ë¥¸ ë¶€ë¶„ì— ëŒ€í•´ì„œë„ ì´ì•¼ê¸°í•´ë³¼ê¹Œìš”?" ì™€ ê°™ì´ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì§ˆë¬¸ì„ ìœ ë„í•´ì£¼ì„¸ìš”.
        6.  **ëª¨ë¥¼ ë•ŒëŠ” ì†”ì§í•˜ê²Œ**: ë¶„ì„ ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì— ëŒ€í•œ ì§ˆë¬¸ì„ ë°›ìœ¼ë©´, "ì œê°€ ê°€ì§„ ë¶„ì„ ìë£Œì—ëŠ” í•´ë‹¹ ë‚´ìš©ì´ ì—†ë„¤ìš”. ì£„ì†¡í•˜ì§€ë§Œ ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œê² ì–´ìš”?" ë¼ê³  ì†”ì§í•˜ê³  ì •ì¤‘í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”. ì ˆëŒ€ ì¶”ì¸¡í•´ì„œ ë§í•˜ì§€ ë§ˆì„¸ìš”.

        --- ë¶„ì„ ë¬¸ì„œ ë‚´ìš© ---
        {context}
        --------------------

        --- ì´ì „ ëŒ€í™” ---
        {chat_history}
        ----------------

        ì§ˆë¬¸: {question}
        ìŒì•… íë ˆì´í„° 'ì˜¤ë³´'ì˜ ë‹µë³€:
        """
        
        PROMPT = PromptTemplate(
            template=prompt_template, input_variables=["context", "chat_history", "question"]
        )

        chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=self.vector_store.as_retriever(search_kwargs={'k': 5}),
            memory=ConversationBufferMemory(memory_key="chat_history", return_messages=True, output_key='answer'),
            combine_docs_chain_kwargs={"prompt": PROMPT},
            verbose=False
        )
        print("âœ… ëŒ€í™”í˜• ì±—ë´‡ ì²´ì¸ ì„¤ì • ì™„ë£Œ.")
        return chain

    def get_response(self, user_query: str) -> str:
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            result = self.chain.invoke({"question": user_query})
            return result.get('answer', "ë‹µë³€ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ğŸš¨ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API í‚¤ë‚˜ ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

# ì „ì—­ ë³€ìˆ˜ë¡œ ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
try:
    chatbot_instance = OboeChatbot()
except Exception as e:
    print(f"ğŸš¨ ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    chatbot_instance = None