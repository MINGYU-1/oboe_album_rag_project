import os
from dotenv import load_dotenv
from pathlib import Path

# LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import ConversationalRetrievalChain
from langchain.prompts import PromptTemplate
from langchain_community.document_loaders import PyPDFLoader
from langchain.memory import ConversationBufferMemory

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class OboeChatbot:
    """
    'ì˜¤ë³´ì—' ì•¨ë²” ë¶„ì„ PDFë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ëŠ” RAG ì±—ë´‡ í´ë˜ìŠ¤
    """
    def __init__(self):
        # .env íŒŒì¼ì—ì„œ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
        self.pdf_filename = os.getenv("PDF_FILENAME")
        
        # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ì´ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ PDF íŒŒì¼ ê²½ë¡œ ì„¤ì •
        base_dir = Path(__file__).parent
        self.pdf_path = base_dir / self.pdf_filename
        
        # ë²¡í„° ìŠ¤í† ì–´ ë° ëŒ€í™” ì²´ì¸ ì´ˆê¸°í™”
        self.vector_store = self._get_or_create_vector_store()
        self.chain = self._setup_conversational_chain()

    def _get_or_create_vector_store(self):
        """PDF íŒŒì¼ë¡œë¶€í„° ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.pdf_path.exists():
            raise FileNotFoundError(
                f"'{self.pdf_filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                f"backend í´ë”ì— íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
            )
        
        try:
            loader = PyPDFLoader(str(self.pdf_path))
            documents = loader.load()
            
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
            split_docs = text_splitter.split_documents(documents)
            
            embeddings = OpenAIEmbeddings()
            vectorstore = FAISS.from_documents(split_docs, embedding=embeddings)
            
            print("âœ… PDF ë¬¸ì„œ ë¡œë“œ ë° ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ.")
            return vectorstore
        except Exception as e:
            print(f"ğŸš¨ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise

    def _setup_conversational_chain(self):
        """LangChainì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™”í˜• ê²€ìƒ‰ ì²´ì¸ì„ ì„¤ì •í•©ë‹ˆë‹¤."""
        llm = ChatOpenAI(model_name="gpt-4o", temperature=0.4, streaming=True)
        
        prompt_template = """
        ë‹¹ì‹ ì€ ì–‘í™ì›ì˜ 'ì˜¤ë³´ì—' ì•¨ë²” ë¶„ì„ ë¬¸ì„œë¥¼ ì™„ë²½íˆ ìˆ™ì§€í•œ ì „ë¬¸ AI ìŒì•… í‰ë¡ ê°€ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ 'ë¶„ì„ ë¬¸ì„œ ë‚´ìš©'ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìì˜ 'ì§ˆë¬¸'ì— ëŒ€í•´ ê¹Šì´ ìˆê³  í†µì°°ë ¥ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        ë‹µë³€ì€ ë°˜ë“œì‹œ ë¬¸ì„œ ë‚´ìš©ì— ê·¼ê±°í•´ì•¼ í•˜ë©°, ì—†ëŠ” ë‚´ìš©ì€ ì ˆëŒ€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
        ì¹œì ˆí•˜ê³  ì „ë¬¸ì ì¸ ë§íˆ¬ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

        --- ë¶„ì„ ë¬¸ì„œ ë‚´ìš© ---
        {context}
        --------------------

        --- ì´ì „ ëŒ€í™” ---
        {chat_history}
        ----------------

        ì§ˆë¬¸: {question}
        ì „ë¬¸ê°€ ë‹µë³€:
        """
        
        PROMPT = PromptTemplate(
            template=prompt_template, input_variables=["context", "chat_history", "question"]
        )

        chain = ConversationalRetrievalChain.from_llm(
            llm=llm,
            retriever=self.vector_store.as_retriever(search_kwargs={'k': 5}),
            memory=ConversationBufferMemory(memory_key="chat_history", return_messages=True, output_key='answer'),
            combine_docs_chain_kwargs={"prompt": PROMPT},
            verbose=False
        )
        print("âœ… ëŒ€í™”í˜• ì±—ë´‡ ì²´ì¸ ì„¤ì • ì™„ë£Œ.")
        return chain

    def get_response(self, user_query: str) -> str:
        """ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            result = self.chain.invoke({"question": user_query})
            return result.get('answer', "ë‹µë³€ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ğŸš¨ ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API í‚¤ë‚˜ ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

# ì „ì—­ ë³€ìˆ˜ë¡œ ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
try:
    chatbot_instance = OboeChatbot()
except Exception as e:
    print(f"ğŸš¨ ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    chatbot_instance = None